<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Kevin Shain</title>
    <meta name="viewport" content="width=device-width; initial-scale=1.0; maximum-scale=1.0;">

    <!-- Combo with CSSNormalize, CSSGrids-Responsive, CSSForm, CSSTable, CSSList (v3.9.1) -->
    <link rel="stylesheet" href="http://yui.yahooapis.com/combo?3.9.1/build/cssnormalize/cssnormalize-min.css&amp;3.9.1/build/cssgrids-responsive/cssgrids-responsive-min.css&amp;3.9.1/build/cssbutton/cssbutton-min.css&amp;gallery-2013.03.27-22-06/build/gallerycss-csslist/gallerycss-csslist-min.css&amp;gallery-2013.03.27-22-06/build/gallerycss-csstable/gallerycss-csstable-min.css&amp;gallery-2013.03.27-22-06/build/gallerycss-cssform/gallerycss-cssform-min.css">
    
    <!-- Some custom styles to make things pretty. -->
    <link rel="stylesheet" type="text/css" href="https://rawgithub.com/tilomitra/prettypages/gh-pages/ui.css">

    <!-- RainbowJS Syntax Highlighting - Github Theme. 
         For more themes, go to https://github.com/ccampbell/rainbow/tree/master/themes -->
    <link rel="stylesheet" type="text/css" href="https://rawgithub.com/ccampbell/rainbow/master/themes/github.css">

    <!-- Modify header colors here to customize the look and feel of the site-->
    <style>
        p { padding: 0; }
        
        .header {
            background: rgb(0, 0, 0);
         }
            .header h1 {
                color: rgb(116, 130, 230);
                ; margin-top: 50px
            }
             .header h2 {
                 font-weight:300;
                 margin-top:0;
                 color: rgb(116, 130, 230);
             }
    	
		h2 { position: relative;}
		h2:before { display: block; content: " "; margin-top: -80px; height: 80px; visibility: hidden; },
		ul:before { display: block; content: " "; margin-top: -50px; height: 50px; visibility: hidden; }

    </style>
    <title>Kevin Shain</title>
  </head>
<body class='yui3-skin-sam'>

    <div id="headerMenu" class="yui3-menu yui3-menu-open yui3-menu-horizontal yui3-menu-fixed">
        <span class="yui3-menu-heading">Kevin Shain</span>
        <ul>
            <li class="yui3-menu-active"><a href="http://kevinshain.github.io/" target="_blank">Home</a></li>
            <li><a href="http://github.com/kevinshain/">My Github</a></li>
            <li><a href="https://www.linkedin.com/in/kevinshain">My LinkedIn</a></li>
            <li><a href="#About">About Me</a></li>
        </ul>
        <ul>
        	<li><a class="yui3-menu-label" href="#Adaptive"><em>Featured Projects:</em></a></li>
            <li><a href="#Adaptive">Adaptive Qubit Measurement</a></li>
            <li><a href="#PCR">PCR Fluorescence Curves</a></li>
            <li><a href="#FTs">Free Throw Prediction</a></li>
            <li><a href="#Kobe">Kobe's Shooting Percentage</a></li>
        </ul>
			
    </div>

    <div class="header yui3-u-1">
        <h1 class="yui3-u-1">Data Science in the Lab</h1>
    </div>
    
    <div class="content">
        <h2 id="Adaptive">An Adaptive Bayesian Algorithm for Optimal Qubit Measurement</h2>
        I did research on quantum computing for a couple of years as an undergrad mainly focusing on hardware that could prolong
        the coherence time of a superconducting qubit (<a href="https://arxiv.org/pdf/1604.06514v1.pdf" target="_blank">link</a>).This
        project tackles decoherence from a data analysis perspective. The adaptive Bayesian algorithm updates the estimate
        of qubit parameter &#916Bz after each measurement and uses that knowledge to optimize the information gained
        from the next measurement.
        <center>
        <p><embed src="Shain_AdaptiveBayesianAlgorithm.pdf" width="600" height="800" alt="pdf" pluginspage="http://www.adobe.com/products/acrobat/readstep2.html" internalinstanceid="9" title=""></p>
		</center>
	</div>	
		
	<div class="content">
        <h2 id="PCR">Qualitative and Quantitative Real-Time PCR analysis</h2>
        Real-time polymerase chain reaction (PCR) data comes in the form of fluorescence curves, the fluorescence signal at each cycle, which indicate the concentration of the analyte. Each cycle should double the concentration of the
        analyte until an ingredient in the reaction is used up. My goals are both a qualitative and quantitative analysis of the fluorescence curves. It is important to industry that there is an extremely robust way of distinguishing the presence of
        some biological molecule. This has proved to be tricky and human graders are still employed to separate positive from negative curves. The root of the problem is often the variable background signal, so I am attempting to build a classified 
        on top of the <a href="https://www.abbottmolecular.com/maxratio-data-analysis.html" target="_blank">maxRatio</a> algorithm which nicely handles the data baselining. For the quantitative analysis, I am investigating the raw fluorescence curves
        to find the initial concentration of the analyte. The initial concentration is calculated based on the cycle number when the fluorescence signal exceeds the background, but finding that cycle number is a challenge. Because this research is going 
        towards a publication, I cannot show the analysis yet.
	</div>
	<div class="content">
        <h2 id="FTs">Free Throw Prediction using Play-by-play Data</h2>
		Seemingly mundane and often frustrating to watch, they account for 2/3 of the winning team's points in the last minute, free throws are one of the most statistically interesting acts in sports. At every level of basketball, free throw shooting has remained remarkably constant over time. For the past fifty years, the league-wide
		free throw percentage has always been within a few percent of its average of 74.9%. That the highest league-wide percentage was 77.1% occurring in 1974 is remarkable. With the exception of records like wins by a pitcher in baseball, which reflect a huge change in the way the game is played, most records have been broken in
		the modern era of advanced training regimens and PEDs. Even sports that don't require exceptional athleticism, like bowling, have seen advances from improving technique. In this respect, free throw shooting is unique.	
		<br><br>
		Estimating the free throw shooting percentage of a player is particularly important for coaches to decide who to play for their team and who to foul on the opposing team. 
		Coaches use the heuristic that players tend to shoot 10% worse in games than practice due to pressure and fatigue. They also consider past performance in similar situations, but not in a methodical way. To allow for methodical analysis,
		I have assembled the largest and most complete database of NBA free throws along with situational information. Since 2001, the NBA has included play-by-play information with the box scores to help fans follow the game. Using this information,
		I was able to scrape all free throws shot since 2001 as well as situational data such as game time, venue, opponent, score, number of the free throw in a given trip to the line, and whether the it was a technical free throw. This is all assembled in
		a PostgreSQL database containing approximately one million shots. In addition to this data, I also assembled season and career statistics on all players since 1950. Finally, I used the play-by-play data to generate a snapshot of each player's statistical
		history exactly as it would be available to a coach at the time of a free throw being attempted. Throughout the process of making a prediction tool, which will be detailed later, I was especially careful to obey the flow of time by removing future data from the
		prediction of any given free throw.
		<br><br>
		Before getting to prediction, the play-by-play data enables us to probe some of the heuristics that coaches use to make gametime decisions. 
		First, while fatigue seems to play a role as free throw percentage decreases by 1% in the fourth quarter, it spikes to 77.4% in the last minute of the game, presumably due to the best shooters being on the floor. Also, there is a consistent decrease of 2-3% for the first few minutes of each quarter.
		This may indicate that players take some time to warm up, further supported by the second free throw of a pair being made 4.6% more often than the first free throw. Seeing these large effects in the league-wide free throw percentages motivates that situational information can
		be used to better predict a player's likelihood to make a free throw at any point during the game. In addition to being interesting in its own right, this prediction tool is useful for coaches to better decide which players to play in a given situation and which opposing players
		to foul. So far, a tuned random forest classifier with situational data yields free throw percentages around 3% better than just using season and career data. While there is still room for better models considering the new dataset at our disposal, the current 3% improvement 
		is definitely enough influence strategic decisions as differences between players' free throw percentages are often within a few points.
		
	</div>
	<div class="content">
        <h2 id="Kobe">Kobe Bryant's Shooting Percentage Kaggle Competition</h2>
		In honor of Kobe Bryant retiring from the NBA after playing for 20 years, Kaggle hosted a competition to predict his likelihood of making various shots. The data was already very clean, so the main effort went into feature engineering and 
		evaluating different types of classifiers. Much of the data was qualitative categories of shot type, action type, or opponent, each of which had many options. I handled this using dummy variables corresponding to each option in each category, 
		which Pandas makes very simple. Some of the classifiers I tried were random forests, gradient boosting, and adaptive boosting, with a carefully tuned random forest performing the best. The classifiers were evaluated using 10-fold cross validation 
		and the log-loss metric. I was trying to predict a chance of making the shot, but in the data, the shot is either a make (1) or miss (0). Therefore, the log-loss makes sense as a metric because it penalizes more if the prediction is confidently wrong. 
		You can view my analysis in the iPython notebook. There is nothing wild about the approach, but this shows that sensible feature engineering and cross validation is enough to reach 4th place out of over 1000 on the public leaderboard.
	</div>
		<hr style="height:4px;border:none;color:#525252;background-color:#525252;" />
		<h2 id="About">About Me</h2>
		<img style="margin-right:20px" height="148" width="140" src="me.jpg" align="left">
		I'm currently a PhD student in Physics at Harvard University. I do experimental research on the
		quantum anomalous Hall effect, quantum spin Hall effect, and graphene in the <a href="http://yacoby.physics.harvard.edu" target="_blank">Yacoby group<a/>. As an undergrad,
		I worked in the <a href="http://rsl.yale.edu" target="_blank">Schoelkopf Lab<a/> at Yale University and developed a Purcell filter to 
		increase the coherence time of superconducting qubits (<a href="http://scitation.aip.org/content/aip/journal/apl/109/4/10.1063/1.4959241" target="_blank">paper<a/>).

        <!-- TYPEKIT -->
        <script type="text/javascript" src="//use.typekit.net/ajf8ggy.js"></script>
        <script type="text/javascript">try{Typekit.load();}catch(e){}</script>
        <script src="https://rawgithub.com/ccampbell/rainbow/master/js/rainbow.min.js"></script>
        <script src="https://rawgithub.com/ccampbell/rainbow/master/js/language/generic.js"></script>
    </div>
</body>
</html>
